{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Approach:\
=========\
\
Since there were no column names given, My model totally depends on model ensembling, the\
Feature were too close for 0 and 2 class, so the accuracy dint improve much.\
\
1) Random Forest\
2) Logistic Regression\
3) Naive bayes\
4) Xgboost\
\
I have also clustered the dataset using means with 3 centers. Took the ratio of few variables. Couldn\'92t do much feature engineering, tried to get a feature from id but it dint work out.\
\
I have used R for programming the models.}